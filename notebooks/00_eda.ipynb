{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fec0e93",
   "metadata": {},
   "source": [
    "# 00 — EDA & Data Health Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.config import load_config\n",
    "from src.schemas import PATHS, get_schema\n",
    "from src.data_io import (\n",
    "    load_train_sessions, load_test_sessions, \n",
    "    load_content_metadata, load_content_price_rate_review, load_content_search_log, load_content_sitewide_log, load_content_top_terms_log,\n",
    "    load_user_metadata, load_user_search_log, load_user_sitewide_log, load_user_top_terms_log, load_user_fashion_search_log, load_user_fashion_sitewide_log,\n",
    "    load_term_search_log, build_time_range_filter, memory_mb\n",
    ")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 5)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "cfg = load_config(\"configs/params.yaml\")\n",
    "data_dir = Path(cfg.paths.data_dir)\n",
    "figures_dir = Path(\"runs/eda/images\"); figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def exists(key: str) -> bool:\n",
    "    rel = PATHS[key]\n",
    "    return (data_dir / rel).exists()\n",
    "\n",
    "def safe_load(fn, key, **kwargs):\n",
    "    if not exists(key):\n",
    "        print(f\"[SKIP] {key}: file not found at {data_dir / PATHS[key]}\")\n",
    "        return None\n",
    "    try:\n",
    "        return fn(data_dir, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] loading {key}: {e}\")\n",
    "        return None\n",
    "\n",
    "def quick_info(df: pd.DataFrame, name: str):\n",
    "    if df is None:\n",
    "        print(f\"{name}: None\")\n",
    "        return\n",
    "    print(f\"{name}: shape={df.shape}, mem={memory_mb(df):.2f} MB\")\n",
    "    display(df.head(3))\n",
    "    display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee2ed6",
   "metadata": {},
   "source": [
    "## 1. Load core tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = safe_load(load_train_sessions, \"train_sessions\")\n",
    "test  = safe_load(load_test_sessions, \"test_sessions\")\n",
    "content_meta = safe_load(load_content_metadata, \"content_metadata\")\n",
    "user_meta    = safe_load(load_user_metadata, \"user_metadata\")\n",
    "\n",
    "# Optional logs (may be large; load minimal columns for EDA)\n",
    "content_site = safe_load(load_content_sitewide_log, \"content_sitewide_log\", columns=[\"date\",\"total_click\",\"total_cart\",\"total_fav\",\"total_order\",\"content_id_hashed\"])\n",
    "user_site    = safe_load(load_user_sitewide_log, \"user_sitewide_log\", columns=[\"ts_hour\",\"total_click\",\"total_cart\",\"total_fav\",\"total_order\",\"user_id_hashed\"])\n",
    "term_log     = safe_load(load_term_search_log, \"term_search_log\")\n",
    "\n",
    "for name, df in [(\"train\", train), (\"test\", test), (\"content_meta\", content_meta), (\"user_meta\", user_meta)]:\n",
    "    quick_info(df, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2273836",
   "metadata": {},
   "source": [
    "## 2. Time ranges & timezone sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd0599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def time_summary(df, ts_col, name):\n",
    "    if df is None or ts_col not in df.columns: \n",
    "        print(f\"[SKIP] {name}\")\n",
    "        return None\n",
    "    tz = str(df[ts_col].dt.tz) if hasattr(df[ts_col].dt, \"tz\") else \"NA\"\n",
    "    print(f\"{name}: tz={tz}, min={df[ts_col].min()}, max={df[ts_col].max()}, rows={len(df):,}\")\n",
    "    return df[ts_col]\n",
    "\n",
    "tr_train = time_summary(train, \"ts_hour\", \"train.ts_hour\")\n",
    "tr_test  = time_summary(test, \"ts_hour\", \"test.ts_hour\")\n",
    "\n",
    "if tr_train is not None:\n",
    "    tr_train.dt.date.value_counts().sort_index().plot(kind=\"line\", title=\"Train daily row counts\")\n",
    "    plt.tight_layout(); plt.savefig(figures_dir / \"train_daily_counts.png\"); plt.show()\n",
    "if tr_test is not None:\n",
    "    tr_test.dt.date.value_counts().sort_index().plot(kind=\"line\", title=\"Test daily row counts\")\n",
    "    plt.tight_layout(); plt.savefig(figures_dir / \"test_daily_counts.png\"); plt.show()\n",
    "\n",
    "# Non-overlap heuristic\n",
    "if tr_train is not None and tr_test is not None:\n",
    "    print(\"Time overlap:\", not (tr_train.max() < tr_test.min() or tr_test.max() < tr_train.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeca854",
   "metadata": {},
   "source": [
    "## 3. Label prevalence & session readiness for AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8175a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train is not None:\n",
    "    click_rate  = float((train[\"clicked\"]==1).mean())\n",
    "    order_rate  = float((train[\"ordered\"]==1).mean())\n",
    "    print(f\"Row-level click_rate={click_rate:.4f}, order_rate={order_rate:.4f}\")\n",
    "\n",
    "    # Session-level: fraction of sessions with at least one positive (needed for AUC per-session)\n",
    "    sess = train.groupby(\"session_id\").agg(\n",
    "        any_click=(\"clicked\", \"max\"),\n",
    "        any_order=(\"ordered\", \"max\"),\n",
    "        n_items=(\"content_id_hashed\", \"count\")\n",
    "    ).reset_index()\n",
    "    print(f\"Sessions: total={len(sess):,}, with_click={sess.any_click.mean():.4f}, with_order={sess.any_order.mean():.4f}\")\n",
    "    sess[\"n_items\"].plot(kind=\"hist\", bins=50, title=\"Items per session (train)\")\n",
    "    plt.tight_layout(); plt.savefig(figures_dir / \"items_per_session.png\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30343f5",
   "metadata": {},
   "source": [
    "## 4. Nulls, dtypes, and candidate keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_summary(df, name):\n",
    "    if df is None: \n",
    "        print(f\"[SKIP] {name}\"); \n",
    "        return\n",
    "    ns = df.isna().mean().sort_values(ascending=False)\n",
    "    print(f\"Null ratio (top 20) — {name}\")\n",
    "    display(ns.head(20).to_frame(\"null_ratio\"))\n",
    "\n",
    "null_summary(train, \"train\")\n",
    "null_summary(test, \"test\")\n",
    "null_summary(content_meta, \"content_meta\")\n",
    "null_summary(user_meta, \"user_meta\")\n",
    "\n",
    "# Candidate uniqueness: (session_id, content_id_hashed) in train\n",
    "if train is not None:\n",
    "    key_dupes = train.duplicated(subset=[\"session_id\",\"content_id_hashed\"]).sum()\n",
    "    print(f\"Train candidate key dupes (session_id, content_id_hashed): {key_dupes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3d1a6",
   "metadata": {},
   "source": [
    "## 5. Cardinality of categorical-like columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinality(df, cols, name):\n",
    "    if df is None: \n",
    "        print(f\"[SKIP] {name}\"); \n",
    "        return\n",
    "    stats = []\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            u = df[c].nunique(dropna=True)\n",
    "            stats.append((c, u))\n",
    "    out = pd.DataFrame(stats, columns=[\"column\",\"nunique\"]).sort_values(\"nunique\", ascending=False)\n",
    "    print(name); display(out)\n",
    "\n",
    "cardinality(train, [\"search_term_normalized\",\"user_id_hashed\",\"content_id_hashed\",\"session_id\"], \"Train cardinalities\")\n",
    "cardinality(content_meta, [\"level1_category_name\",\"level2_category_name\",\"leaf_category_name\",\"content_id_hashed\"], \"Content meta cardinalities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98a071",
   "metadata": {},
   "source": [
    "## 6. Scaled [0,1] columns sanity (logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3481a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scaled01(df, cols, name):\n",
    "    if df is None: \n",
    "        print(f\"[SKIP] {name}\"); \n",
    "        return\n",
    "    bad = {}\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            mn, mx = df[c].min(skipna=True), df[c].max(skipna=True)\n",
    "            if (mn is not None and mn < 0) or (mx is not None and mx > 1):\n",
    "                bad[c] = (mn, mx)\n",
    "    if bad:\n",
    "        print(f\"[WARN] Out-of-[0,1] values in {name}:\", bad)\n",
    "    else:\n",
    "        print(f\"[OK] All {len(cols)} columns within [0,1] in {name}\")\n",
    "\n",
    "check_scaled01(content_site, [\"total_click\",\"total_cart\",\"total_fav\",\"total_order\"], \"content_sitewide_log\")\n",
    "check_scaled01(user_site, [\"total_click\",\"total_cart\",\"total_fav\",\"total_order\"], \"user_sitewide_log\")\n",
    "if term_log is not None:\n",
    "    check_scaled01(term_log, [\"total_search_impression\",\"total_search_click\"], \"term_search_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61433e2e",
   "metadata": {},
   "source": [
    "## 7. Basic distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if content_meta is not None and \"content_rate_avg\" in (content_meta.columns if 'content_rate_avg' in content_meta.columns else []):\n",
    "    pass  # handled in price/rating dataset below\n",
    "prr = safe_load(load_content_price_rate_review, \"content_price_rate_review\", columns=[\n",
    "    \"update_date\",\"original_price\",\"selling_price\",\"discounted_price\",\"content_rate_avg\",\"content_rate_count\",\"content_id_hashed\"\n",
    "])\n",
    "if prr is not None:\n",
    "    prr[\"selling_price\"].dropna().plot(kind=\"hist\", bins=50, title=\"Selling price distribution\")\n",
    "    plt.tight_layout(); plt.savefig(figures_dir / \"selling_price_hist.png\"); plt.show()\n",
    "    prr[\"content_rate_avg\"].dropna().plot(kind=\"hist\", bins=50, title=\"Rating average distribution\")\n",
    "    plt.tight_layout(); plt.savefig(figures_dir / \"rating_avg_hist.png\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20195b5d",
   "metadata": {},
   "source": [
    "## 8. Search term & CTR glimpses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56869712",
   "metadata": {},
   "outputs": [],
   "source": [
    "if term_log is not None:\n",
    "    df = term_log.copy()\n",
    "    df[\"ctr\"] = df[\"total_search_click\"] / (df[\"total_search_impression\"] + 1e-9)\n",
    "    # Top 20 terms by impression\n",
    "    top = (df.groupby(\"search_term_normalized\")[\"total_search_impression\"]\n",
    "             .sum().sort_values(ascending=False).head(20))\n",
    "    display(top.to_frame(\"imp_sum\"))\n",
    "    top.index.to_series().reset_index(drop=True).to_frame(\"term\").plot(kind=\"bar\", title=\"Top-20 terms (by impression)\"); plt.tight_layout()\n",
    "    plt.savefig(figures_dir / \"top_terms_bar.png\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f96427",
   "metadata": {},
   "source": [
    "## 9. Leakage risk checklist (static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = [\n",
    "  \"- All joins in features must use logs up to and including `ts_hour` (no future rows).\",\n",
    "  \"- Target encoding must be fit in a fold-out-of-fold manner (no same-fold target leakage).\",\n",
    "  \"- Do not use row-level labels from the same session to build features for other items within that session.\",\n",
    "  \"- Ensure CV uses a purge gap of at least 24h between train and validation splits.\",\n",
    "  \"- Verify no columns (e.g., explicit future price updates) reference times after `ts_hour`.\",\n",
    "]\n",
    "print(\"\\n\".join(checks))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
